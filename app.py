import streamlit as st
import re
import os
from datetime import datetime
from dataclasses import dataclass, field
from typing import List
from docx import Document
import io
import anthropic

RULE_VERSION = "2026-02-04"
BRIEF_VERSION = "2026-02"

BRIEF_CONTENT = """
**æ ¸å¿ƒå–ç‚¹ (ä¸å¯æ”¹åŠ¨):**
- å¤šé¡¹ç§‘å­¦å®è¯çš„é›€å·¢å°–å³°æ°´è§£æŠ€æœ¯
- é˜²æ•é¢†åŸŸæƒå¨å¾·å›½GINIç ”ç©¶è®¤è¯
- èƒ½é•¿æ•ˆé˜²æ•20å¹´
- ç›¸æ¯”äºç‰›å¥¶è›‹ç™½è‡´æ•æ€§é™ä½1000å€
- å…¨çƒåˆ›æ–°çš„è¶…å€è‡ªæŠ¤ç§‘æŠ€
- 6ç§HMOåŠ ä¸Šæ˜æ˜ŸåŒèŒB.Infantiså’ŒBb-12
- ååŒä½œç”¨é‡Šæ”¾é«˜å€çš„åŸç”Ÿä¿æŠ¤åŠ›
- çŸ­çŸ­28å¤©å°±èƒ½è°ƒç†å¥½å¨ƒçš„è‚šè‚šèŒèŒç¯å¢ƒ
- ä¿æŠ¤åŠ›èƒ½æŒç»­15ä¸ªæœˆ
- 25ç§ç»´ç”Ÿç´ å’ŒçŸ¿ç‰©è´¨
- å…¨ä¹³ç³–çš„é…æ–¹å£å‘³æ¸…æ·¡
"""

REVIEW_RULES = {
    "required_keywords": ["é€‚åº¦æ°´è§£", "é˜²æ•", "èƒ½æ©å…¨æŠ¤"],
    "forbidden_words": {
        "ç¦æ­¢è¯": ["æ•å®", "å¥¶ç“¶", "å¥¶å˜´", "æ–°ç”Ÿå„¿", "è¿‡æ•", "ç–¾ç—…"],
        "ç¦ç–—æ•ˆ": ["é¢„é˜²", "ç”Ÿé•¿", "å‘è‚²", "å…ç–«"],
        "ç¦ç»å¯¹åŒ–": ["æœ€å¥½", "æœ€ä½³", "TOP1", "No.1"]
    },
    "allowed_exceptions": ["ç¬¬ä¸€å£å¥¶ç²‰", "ç¬¬ä¸€å£é…æ–¹ç²‰"],
    "selling_points": [
        "å¤šé¡¹ç§‘å­¦å®è¯çš„é›€å·¢å°–å³°æ°´è§£æŠ€æœ¯",
        "é˜²æ•é¢†åŸŸæƒå¨å¾·å›½GINIç ”ç©¶è®¤è¯",
        "èƒ½é•¿æ•ˆé˜²æ•20å¹´",
        "ç›¸æ¯”äºç‰›å¥¶è›‹ç™½è‡´æ•æ€§é™ä½1000å€",
        "å…¨çƒåˆ›æ–°çš„è¶…å€è‡ªæŠ¤ç§‘æŠ€",
        "6ç§HMOåŠ ä¸Šæ˜æ˜ŸåŒèŒB.Infantiså’ŒBb-12",
        "ååŒä½œç”¨é‡Šæ”¾é«˜å€çš„åŸç”Ÿä¿æŠ¤åŠ›",
        "çŸ­çŸ­28å¤©å°±èƒ½è°ƒç†å¥½å¨ƒçš„è‚šè‚šèŒèŒç¯å¢ƒ",
        "ä¿æŠ¤åŠ›èƒ½æŒç»­15ä¸ªæœˆ",
        "25ç§ç»´ç”Ÿç´ å’ŒçŸ¿ç‰©è´¨",
        "å…¨ä¹³ç³–çš„é…æ–¹å£å‘³æ¸…æ·¡"
    ],
    "required_tags": ["#èƒ½æ©å…¨æŠ¤", "#èƒ½æ©å…¨æŠ¤æ°´å¥¶", "#é€‚åº¦æ°´è§£", "#é€‚åº¦æ°´è§£å¥¶ç²‰", "#é€‚åº¦æ°´è§£å¥¶ç²‰æ¨è", "#é˜²æ•å¥¶ç²‰", "#ç¬¬ä¸€å£å¥¶ç²‰", "#é›€å·¢é€‚åº¦æ°´è§£"],
    "max_words": 900,
    "min_tags": 10
}

SUGGESTIONS = {"æ•å®": "æ•æ„Ÿä½“è´¨å®å®", "æ–°ç”Ÿå„¿": "åˆç”Ÿå®å®", "è¿‡æ•": "æ•æ•", "é¢„é˜²": "è¿œç¦»", "ç”Ÿé•¿": "æˆé•¿", "å‘è‚²": "æˆé•¿", "å…ç–«": "ä¿æŠ¤åŠ›"}

@dataclass
class CheckResult:
    name: str
    passed: bool
    found: int = 0
    total: int = 0
    issues: List[str] = field(default_factory=list)

def read_docx(file):
    doc = Document(io.BytesIO(file.read()))
    text = []
    for para in doc.paragraphs:
        if para.text.strip():
            text.append(para.text)
    return "\n".join(text)

def parse_content(content):
    tags = re.findall(r'#[\w\u4e00-\u9fff]+', content)
    text = re.sub(r'#[\w\u4e00-\u9fff]+', '', content)
    word_count = len(re.findall(r'[\u4e00-\u9fff]', text))
    return {"text": content, "tags": tags, "word_count": word_count}

def run_review(content, kol, ver, reviewer):
    data = parse_content(content)
    results = {}
    
    kw_issues = []
    kw_found = 0
    for kw in REVIEW_RULES["required_keywords"]:
        if kw in data["text"]:
            kw_found += 1
        else:
            kw_issues.append(f"ç¼ºå°‘: {kw}")
    results["keywords"] = CheckResult("å¿…é¡»å…³é”®è¯", len(kw_issues)==0, kw_found, len(REVIEW_RULES["required_keywords"]), kw_issues)
    
    fb_issues = []
    exceptions = REVIEW_RULES["allowed_exceptions"]
    for cat, words in REVIEW_RULES["forbidden_words"].items():
        for w in words:
            if w in data["text"]:
                ctx = data["text"][max(0,data["text"].find(w)-10):data["text"].find(w)+len(w)+10]
                if not any(e in ctx for e in exceptions):
                    sug = SUGGESTIONS.get(w, "åˆ é™¤")
                    fb_issues.append(f"{cat} [{w}] - {sug}")
    results["forbidden"] = CheckResult("ç¦è¯æ£€æŸ¥", len(fb_issues)==0, 0, 0, fb_issues)
    
    sp_issues = []
    sp_found = 0
    for sp in REVIEW_RULES["selling_points"]:
        if sp in data["text"]:
            sp_found += 1
        else:
            sp_issues.append(f"ç¼ºå°‘: {sp[:20]}...")
    results["selling"] = CheckResult("ä¸å¯æ”¹åŠ¨å–ç‚¹", sp_found==len(REVIEW_RULES["selling_points"]), sp_found, len(REVIEW_RULES["selling_points"]), sp_issues)
    
    st_issues = []
    if data["word_count"] > REVIEW_RULES["max_words"]:
        st_issues.append(f"å­—æ•°è¶…é™: {data['word_count']}/{REVIEW_RULES['max_words']}")
    if len(data["tags"]) < REVIEW_RULES["min_tags"]:
        st_issues.append(f"æ ‡ç­¾ä¸è¶³: {len(data['tags'])}/{REVIEW_RULES['min_tags']}")
    results["structure"] = CheckResult("ç»“æ„å®Œæ•´æ€§", len(st_issues)==0, 0, 0, st_issues)
    
    tg_issues = []
    tg_found = 0
    for t in REVIEW_RULES["required_tags"]:
        if t in data["tags"]:
            tg_found += 1
        else:
            tg_issues.append(f"ç¼ºå°‘: {t}")
    results["tags"] = CheckResult("å¿…æTag", len(tg_issues)==0, tg_found, len(REVIEW_RULES["required_tags"]), tg_issues)
    
    score = 0
    weights = [("keywords", 0.15), ("forbidden", 0.20), ("selling", 0.30), ("structure", 0.15), ("tags", 0.20)]
    for key, w in weights:
        r = results[key]
        if r.total > 0:
            score += (r.found / r.total) * w * 100
        else:
            score += (100 if r.passed else 0) * w
    
    return {"kol": kol, "ver": ver, "reviewer": reviewer, "results": results, "score": round(score, 1), "word_count": data["word_count"], "tag_count": len(data["tags"])}

def get_ai_suggestions(content, issues):
    api_key = os.environ.get("ANTHROPIC_API_KEY")
    if not api_key:
        return None, None
    
    issues_text = "\n".join([f"- {issue}" for issue in issues])
    selling_points_text = "\n".join([f"- {sp}" for sp in REVIEW_RULES["selling_points"]])
    
    prompt = f"""ä½ æ˜¯å°çº¢ä¹¦KOLç¨¿ä»¶å®¡æ ¸ä¸“å®¶ã€‚è¯·ä¿®æ”¹ä»¥ä¸‹ç¨¿ä»¶ã€‚

åŸç¨¿ä»¶:
{content}

å‘ç°çš„é—®é¢˜:
{issues_text}

å¿…é¡»åŒ…å«çš„å–ç‚¹(ä¸å¯æ”¹åŠ¨åŸæ–‡):
{selling_points_text}

ç¦è¯æ›¿æ¢: æ•å®æ”¹ä¸ºæ•æ„Ÿä½“è´¨å®å®, æ–°ç”Ÿå„¿æ”¹ä¸ºåˆç”Ÿå®å®, è¿‡æ•æ”¹ä¸ºæ•æ•, é¢„é˜²æ”¹ä¸ºè¿œç¦», ç”Ÿé•¿å‘è‚²æ”¹ä¸ºæˆé•¿, å…ç–«æ”¹ä¸ºä¿æŠ¤åŠ›

ä»»åŠ¡1: åˆ—å‡ºä¿®æ”¹å»ºè®®,æ ¼å¼ä¸º:
é—®é¢˜: xxx
åŸæ–‡: xxx  
æ”¹ä¸º: xxx

ä»»åŠ¡2: è¾“å‡ºä¿®æ”¹åçš„å®Œæ•´ç¨¿ä»¶

è¯·ç”¨ä»¥ä¸‹æ ¼å¼å›å¤:

SUGGESTIONS_START
(ä¿®æ”¹å»ºè®®)
SUGGESTIONS_END

REVISED_START
(å®Œæ•´ç¨¿ä»¶)
REVISED_END
"""
    
    try:
        client = anthropic.Anthropic(api_key=api_key)
        message = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4000,
            messages=[{"role": "user", "content": prompt}]
        )
        response = message.content[0].text
        
        suggestions = ""
        revised = ""
        
        if "SUGGESTIONS_START" in response and "SUGGESTIONS_END" in response:
            start = response.find("SUGGESTIONS_START") + len("SUGGESTIONS_START")
            end = response.find("SUGGESTIONS_END")
            suggestions = response[start:end].strip()
        
        if "REVISED_START" in response and "REVISED_END" in response:
            start = response.find("REVISED_START") + len("REVISED_START")
            end = response.find("REVISED_END")
            revised = response[start:end].strip()
        
        return suggestions, revised
    except Exception as e:
        return f"AI error: {str(e)}", None

st.set_page_config(page_title="å°çº¢ä¹¦KOLå®¡ç¨¿ç³»ç»Ÿ", page_icon="ğŸ”", layout="wide")
st.markdown("<h1 style='text-align:center;color:#ff6b6b;'>å°çº¢ä¹¦KOLå®¡ç¨¿ç³»ç»Ÿ v2.1</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center;color:gray;'>èƒ½æ©å…¨æŠ¤ - AIæ™ºèƒ½å®¡æ ¸</p>", unsafe_allow_html=True)
st.markdown("---")

c1, c2 = st.columns(2)
c1.info(f"å®¡æ ¸è§„åˆ™: {RULE_VERSION}")
c2.info(f"Brief: {BRIEF_VERSION}")

with st.expander("æŸ¥çœ‹Briefå†…å®¹"):
    st.markdown(BRIEF_CONTENT)

st.markdown("---")

c1, c2, c3 = st.columns(3)
kol = c1.text_input("KOLåç§°", placeholder="ä¾‹å¦‚: å°çº¢è–¯å¦ˆå¦ˆ")
ver = c2.selectbox("ç‰ˆæœ¬", ["V1", "V2", "V3", "FINAL"])
reviewer = c3.selectbox("å®¡æ ¸æ–¹", ["èµæ„", "å®¢æˆ·"])

st.markdown("### ç¨¿ä»¶å†…å®¹")

tab1, tab2 = st.tabs(["ä¸Šä¼ æ–‡æ¡£", "ç²˜è´´æ–‡æœ¬"])

content = ""

with tab1:
    uploaded_file = st.file_uploader("ä¸Šä¼ Wordæ–‡æ¡£", type=["docx"])
    if uploaded_file:
        content = read_docx(uploaded_file)
        st.success(f"å·²è¯»å–: {uploaded_file.name}")
        with st.expander("é¢„è§ˆå†…å®¹"):
            st.text(content[:500] + "..." if len(content) > 500 else content)

with tab2:
    pasted = st.text_area("ç²˜è´´ç¨¿ä»¶å†…å®¹", height=250, placeholder="ç²˜è´´ç¨¿ä»¶...")
    if pasted:
        content = pasted

if st.button("å¼€å§‹å®¡æ ¸", type="primary", use_container_width=True):
    if not kol:
        st.error("è¯·å¡«å†™KOLåç§°")
    elif not content.strip():
        st.error("è¯·ä¸Šä¼ æ–‡æ¡£æˆ–ç²˜è´´å†…å®¹")
    else:
        r = run_review(content, kol, ver, reviewer)
        
        st.markdown("---")
        st.markdown("## å®¡æ ¸æŠ¥å‘Š")
        
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("KOL", f"@{r['kol']}")
        c2.metric("ç‰ˆæœ¬", r['ver'])
        c3.metric("å®¡æ ¸æ–¹", r['reviewer'])
        c4.metric("ç»¼åˆè¯„åˆ†", f"{r['score']}%")
        
        st.markdown("---")
        st.markdown("## ä¸€ã€å®¢è§‚æ£€æŸ¥")
        
        checks = [
            ("1.1 å¿…é¡»å…³é”®è¯", "keywords"),
            ("1.2 ç¦è¯æ£€æŸ¥", "forbidden"),
            ("1.3 ä¸å¯æ”¹åŠ¨å–ç‚¹", "selling"),
            ("1.4 ç»“æ„å®Œæ•´æ€§", "structure"),
            ("1.5 å¿…æTag", "tags")
        ]
        
        all_issues = []
        for title, key in checks:
            res = r["results"][key]
            if res.total > 0:
                status = f"{res.found}/{res.total}"
            else:
                status = "é€šè¿‡" if res.passed else f"{len(res.issues)}é¡¹é—®é¢˜"
            
            with st.expander(f"{title} - {status}", expanded=not res.passed):
                if res.passed:
                    st.success("é€šè¿‡")
                else:
                    for issue in res.issues:
                        st.warning(issue)
                        all_issues.append(f"[{title}] {issue}")
        
        st.markdown("---")
        st.markdown("## äºŒã€å®¡æ ¸æ€»ç»“")
        
        if r["score"] >= 90:
            st.success("ä¼˜ç§€!")
        elif r["score"] >= 70:
            st.info("è‰¯å¥½")
        elif r["score"] >= 50:
            st.warning("éœ€æ”¹è¿›")
        else:
            st.error("éœ€å¤§æ”¹")
        
        st.caption(f"å­—æ•°: {r['word_count']} | æ ‡ç­¾: {r['tag_count']}ä¸ª")
        
        if all_issues and r["score"] < 90:
            st.markdown("---")
            st.markdown("## ä¸‰ã€AIä¿®æ”¹å»ºè®®")
            
            with st.spinner("AIæ­£åœ¨ç”Ÿæˆä¿®æ”¹å»ºè®®..."):
                suggestions, revised = get_ai_suggestions(content, all_issues)
            
            if suggestions:
                st.markdown("### ä¿®æ”¹å»ºè®®")
                st.markdown(suggestions)
                
                if revised:
                    st.markdown("---")
                    st.markdown("### ä¿®æ”¹åçš„ç¨¿ä»¶")
                    st.text_area("å¯ç›´æ¥å¤åˆ¶", revised, height=300)
                    
                    st.download_button(
                        label="ä¸‹è½½ä¿®æ”¹ç¨¿ä»¶",
                        data=revised,
                        file_name=f"{kol}_{ver}_revised.txt",
                        mime="text/plain"
                    )
            else:
                st.warning("AIæœåŠ¡ä¸å¯ç”¨,è¯·æ£€æŸ¥API Key")

st.markdown("---")
st.caption(f"v2.1 | {RULE_VERSION}")
