import streamlit as st
import re
import os
import json
from datetime import datetime
from docx import Document
import io
import urllib.request

RULE_VERSION = "2026-02-04"
TODAY = datetime.now().strftime("%Y%m%d")

REVIEW_RULES = {
    "required_keywords": ["é€‚åº¦æ°´è§£", "é˜²æ•", "èƒ½æ©å…¨æŠ¤"],
    "forbidden_words": {
        "ç¦æ­¢è¯": ["æ•å®", "å¥¶ç“¶", "å¥¶å˜´", "æ–°ç”Ÿå„¿", "è¿‡æ•", "ç–¾ç—…"],
        "ç¦ç–—æ•ˆ": ["é¢„é˜²", "ç”Ÿé•¿", "å‘è‚²", "å…ç–«"],
        "ç¦ç»å¯¹åŒ–": ["æœ€å¥½", "æœ€ä½³", "TOP1", "No.1"]
    },
    "allowed_exceptions": ["ç¬¬ä¸€å£å¥¶ç²‰", "ç¬¬ä¸€å£é…æ–¹ç²‰"],
    "selling_points": [
        "å¤šé¡¹ç§‘å­¦å®è¯çš„é›€å·¢å°–å³°æ°´è§£æŠ€æœ¯",
        "é˜²æ•é¢†åŸŸæƒå¨å¾·å›½GINIç ”ç©¶è®¤è¯",
        "èƒ½é•¿æ•ˆé˜²æ•20å¹´",
        "ç›¸æ¯”äºç‰›å¥¶è›‹ç™½è‡´æ•æ€§é™ä½1000å€",
        "å…¨çƒåˆ›æ–°çš„è¶…å€è‡ªæŠ¤ç§‘æŠ€",
        "6ç§HMOåŠ ä¸Šæ˜æ˜ŸåŒèŒB.Infantiså’ŒBb-12",
        "ååŒä½œç”¨é‡Šæ”¾é«˜å€çš„åŸç”Ÿä¿æŠ¤åŠ›",
        "çŸ­çŸ­28å¤©å°±èƒ½è°ƒç†å¥½å¨ƒçš„è‚šè‚šèŒèŒç¯å¢ƒ",
        "ä¿æŠ¤åŠ›èƒ½æŒç»­15ä¸ªæœˆ",
        "25ç§ç»´ç”Ÿç´ å’ŒçŸ¿ç‰©è´¨",
        "å…¨ä¹³ç³–çš„é…æ–¹å£å‘³æ¸…æ·¡"
    ],
    "required_tags": ["#èƒ½æ©å…¨æŠ¤", "#èƒ½æ©å…¨æŠ¤æ°´å¥¶", "#é€‚åº¦æ°´è§£", "#é€‚åº¦æ°´è§£å¥¶ç²‰", "#é€‚åº¦æ°´è§£å¥¶ç²‰æ¨è", "#é˜²æ•å¥¶ç²‰", "#ç¬¬ä¸€å£å¥¶ç²‰", "#é›€å·¢é€‚åº¦æ°´è§£"],
    "max_words": 900,
    "min_tags": 10
}

SUGGESTIONS = {"æ•å®": "æ•æ„Ÿä½“è´¨å®å®", "æ–°ç”Ÿå„¿": "åˆç”Ÿå®å®", "è¿‡æ•": "æ•æ•", "é¢„é˜²": "è¿œç¦»", "ç”Ÿé•¿": "æˆé•¿", "å‘è‚²": "æˆé•¿", "å…ç–«": "ä¿æŠ¤åŠ›"}

def read_docx(file):
    doc = Document(io.BytesIO(file.read()))
    text = []
    for para in doc.paragraphs:
        if para.text.strip():
            text.append(para.text)
    return "\n".join(text)

def parse_content(content):
    tags = re.findall(r'#[\w\u4e00-\u9fff]+', content)
    text = re.sub(r'#[\w\u4e00-\u9fff]+', '', content)
    word_count = len(re.findall(r'[\u4e00-\u9fff]', text))
    return {"text": content, "tags": tags, "word_count": word_count}

def run_review(content):
    data = parse_content(content)
    issues = []

    for kw in REVIEW_RULES["required_keywords"]:
        if kw not in data["text"]:
            issues.append({"type": "keyword", "desc": f"ç¼ºå°‘å…³é”®è¯: {kw}", "suggestion": f"è¯·åŠ å…¥ã€Œ{kw}ã€"})

    exceptions = REVIEW_RULES["allowed_exceptions"]
    for cat, words in REVIEW_RULES["forbidden_words"].items():
        for w in words:
            if w in data["text"]:
                idx = data["text"].find(w)
                ctx = data["text"][max(0,idx-10):idx+len(w)+10]
                if not any(e in ctx for e in exceptions):
                    sug = SUGGESTIONS.get(w, "åˆ é™¤")
                    issues.append({"type": "forbidden", "desc": f"ç¦è¯ã€Œ{w}ã€", "context": ctx, "suggestion": f"æ”¹ä¸ºã€Œ{sug}ã€"})

    for sp in REVIEW_RULES["selling_points"]:
        if sp not in data["text"]:
            issues.append({"type": "selling", "desc": f"ç¼ºå°‘å–ç‚¹", "suggestion": f"è¯·åŠ å…¥: {sp}"})

    if data["word_count"] > REVIEW_RULES["max_words"]:
        issues.append({"type": "structure", "desc": f"å­—æ•°è¶…é™: {data['word_count']}/{REVIEW_RULES['max_words']}", "suggestion": "è¯·ç²¾ç®€"})

    if len(data["tags"]) < REVIEW_RULES["min_tags"]:
        issues.append({"type": "structure", "desc": f"æ ‡ç­¾ä¸è¶³: {len(data['tags'])}/{REVIEW_RULES['min_tags']}", "suggestion": "è¯·è¡¥å……"})

    for t in REVIEW_RULES["required_tags"]:
        if t not in data["tags"]:
            issues.append({"type": "tag", "desc": f"ç¼ºå°‘æ ‡ç­¾: {t}", "suggestion": f"è¯·åŠ å…¥ {t}"})

    return issues, data

def call_claude_api(prompt):
    api_key = os.environ.get("ANTHROPIC_API_KEY")
    if not api_key:
        return None
    url = "https://api.anthropic.com/v1/messages"
    headers = {"Content-Type": "application/json", "x-api-key": api_key, "anthropic-version": "2023-06-01"}
    data = {"model": "claude-sonnet-4-20250514", "max_tokens": 4000, "messages": [{"role": "user", "content": prompt}]}
    req = urllib.request.Request(url, data=json.dumps(data).encode('utf-8'), headers=headers)
    try:
        with urllib.request.urlopen(req, timeout=60) as response:
            result = json.loads(response.read().decode('utf-8'))
            return result["content"][0]["text"]
    except Exception as e:
        return f"Error: {str(e)}"

def analyze_client_feedback(original, client_modified):
    prompt = f"""ä½ æ˜¯å°çº¢ä¹¦KOLç¨¿ä»¶å®¡æ ¸ä¸“å®¶ã€‚å¯¹æ¯”åˆ†æå®¢æˆ·ä¿®æ”¹ã€‚

åŸç¨¿ä»¶:
{original}

å®¢æˆ·ä¿®æ”¹å:
{client_modified}

å®¡æ ¸è§„åˆ™: ç¦è¯åŒ…æ‹¬æ•å®ã€å¥¶ç“¶ã€å¥¶å˜´ã€æ–°ç”Ÿå„¿ã€è¿‡æ•ã€ç–¾ç—…ã€é¢„é˜²ã€ç”Ÿé•¿ã€å‘è‚²ã€å…ç–«ã€æœ€å¥½ã€æœ€ä½³ã€‚ä¾‹å¤–:"ç¬¬ä¸€å£å¥¶ç²‰"ä¸­çš„"ç¬¬ä¸€"ä¸ç®—ç¦è¯ã€‚

è¯·åˆ†æå®¢æˆ·ä¿®æ”¹äº†å“ªäº›å†…å®¹,æ¯æ¡æ˜¯å¦ç¬¦åˆè§„åˆ™,ä¸ç¬¦åˆçš„ç»™å»ºè®®ã€‚

æ ¼å¼:
===ä¿®æ”¹åˆ†æ===
ä¿®æ”¹1: [æè¿°]
çŠ¶æ€: ç¬¦åˆ/ä¸ç¬¦åˆ
å»ºè®®: [å»ºè®®]

===æ€»ç»“===
ç¬¦åˆ: Xæ¡
éœ€è°ƒæ•´: Xæ¡
"""
    return call_claude_api(prompt)

def create_annotated_docx(content, issues, selected_issues, kol_name, version, step):
    doc = Document()
    if step == 2:
        title = f"{kol_name}_{TODAY}_KOL-èµæ„_ç¬¬{version}ç‰ˆ"
        subtitle = "èµæ„å®¡æ ¸æ‰¹æ³¨ç‰ˆ"
    else:
        title = f"{kol_name}_{TODAY}_KOL-èµæ„-å®¢æˆ·_ç¬¬{version}ç‰ˆ"
        subtitle = "å®¢æˆ·åé¦ˆå¤„ç†ç‰ˆ"

    doc.add_heading(title, 0)
    doc.add_paragraph(f"å®¡æ ¸æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    doc.add_paragraph(f"æ–‡æ¡£ç±»å‹: {subtitle}")
    doc.add_paragraph("---")

    if selected_issues:
        doc.add_heading("å®¡æ ¸æ„è§", level=1)
        for i, idx in enumerate(selected_issues):
            if idx < len(issues):
                issue = issues[idx]
                p = doc.add_paragraph()
                p.add_run(f"{i+1}. {issue['desc']}").bold = True
                p.add_run(f"\n   å»ºè®®: {issue['suggestion']}")
        doc.add_paragraph("---")

    doc.add_heading("ç¨¿ä»¶å†…å®¹", level=1)
    for line in content.split('\n'):
        if line.strip():
            doc.add_paragraph(line)

    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer, title

st.set_page_config(page_title="èµæ„AIå®¡ç¨¿ç³»ç»Ÿ", page_icon="ğŸ¤–", layout="wide")

st.markdown("""
<style>
.block-container {padding-top: 1rem !important; padding-bottom: 1rem !important;}
[data-testid="column"]:first-child {
    background-color: #fff0f3;
    border-radius: 15px;
    padding: 20px;
    border: 2px solid #ff6b6b;
}
[data-testid="column"]:last-child {
    background-color: #f0fff4;
    border-radius: 15px;
    padding: 20px;
    border: 2px solid #38a169;
}
.step-badge-pink {
    background-color: #ff6b6b;
    color: white;
    padding: 8px 16px;
    border-radius: 20px;
    font-weight: bold;
    font-size: 14px;
}
.step-badge-green {
    background-color: #38a169;
    color: white;
    padding: 8px 16px;
    border-radius: 20px;
    font-weight: bold;
    font-size: 14px;
}
.file-output {
    background-color: #f7fafc;
    border: 1px dashed #cbd5e0;
    padding: 10px;
    border-radius: 8px;
    font-family: monospace;
    margin: 10px 0;
}
</style>
""", unsafe_allow_html=True)

st.markdown("""
<div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 12px; padding: 15px 25px; margin-bottom: 15px;">
    <h2 style="color: white; margin: 0;">ğŸ¤– èµæ„AI Â· å°çº¢ä¹¦KOLå®¡ç¨¿ç³»ç»Ÿ</h2>
    <p style="color: rgba(255,255,255,0.9); margin: 5px 0 0 0; font-size: 15px;">å…”å­å°å§ï¼Œä½ å¥½å‘€ï¼æˆ‘æ˜¯èƒ½æ©å…¨æŠ¤çš„AIæœºå™¨äººï¼Œä¸ºä½ æœåŠ¡~</p>
</div>
""", unsafe_allow_html=True)

col1, col2 = st.columns(2)
with col1:
    kol_name = st.text_input("KOLåç§°", placeholder="ä¾‹å¦‚: å›¢å¦ˆçˆ±æµ‹è¯„")
with col2:
    version_num = st.selectbox("å½“å‰ç‰ˆæœ¬", [1, 2, 3, 4, 5])

st.caption(f"å½“å‰æ—¥æœŸ: {TODAY}")

if 'kol_issues' not in st.session_state:
    st.session_state.kol_issues = []
if 'kol_content' not in st.session_state:
    st.session_state.kol_content = ""
if 'client_analysis' not in st.session_state:
    st.session_state.client_analysis = ""

col_left, col_right = st.columns(2)

with col_left:
    st.markdown('<span class="step-badge-pink">Step 1: KOLç¨¿ä»¶ - èµæ„å®¡æ ¸ - å®Œæ¯•ç»™å®¢æˆ·</span>', unsafe_allow_html=True)
    st.markdown("#### ğŸ“„ ä¸Šä¼ KOLç¨¿ä»¶")

    kol_file = st.file_uploader("ä¸Šä¼  .docx", type=["docx"], key="kol_file")
    kol_text = st.text_area("æˆ–ç²˜è´´å†…å®¹", height=180, placeholder="ç²˜è´´KOLç¨¿ä»¶...", key="kol_text")

    kol_content = ""
    if kol_file:
        kol_file.seek(0)
        kol_content = read_docx(kol_file)
        st.success(f"å·²è¯»å–: {kol_file.name}")
    elif kol_text:
        kol_content = kol_text

    if st.button("å¼€å§‹å®¡ç¨¿", type="primary", key="btn_review", use_container_width=True):
        if not kol_name:
            st.error("è¯·å¡«å†™KOLåç§°")
        elif not kol_content:
            st.error("è¯·ä¸Šä¼ æˆ–ç²˜è´´ç¨¿ä»¶")
        else:
            issues, data = run_review(kol_content)
            st.session_state.kol_issues = issues
            st.session_state.kol_content = kol_content
            st.success(f"å®¡æ ¸å®Œæˆ! å‘ç° {len(issues)} ä¸ªé—®é¢˜")

    if st.session_state.kol_issues:
        st.markdown("#### å®¡æ ¸æ„è§ (å‹¾é€‰é‡‡çº³)")
        selected = []
        for i, issue in enumerate(st.session_state.kol_issues):
            if st.checkbox(f"{issue['desc']}", key=f"iss_{i}", value=True):
                selected.append(i)
            st.caption(f"å»ºè®®: {issue['suggestion']}")

        if kol_name:
            output_name = f"{kol_name}_{TODAY}_KOL-èµæ„_ç¬¬{version_num}ç‰ˆ"
            st.markdown(f'<div class="file-output">ğŸ“ {output_name}.docx</div>', unsafe_allow_html=True)

            if st.button("ç”Ÿæˆæ‰¹æ³¨æ–‡æ¡£", key="btn_gen_kol", use_container_width=True):
                buffer, title = create_annotated_docx(st.session_state.kol_content, st.session_state.kol_issues, selected, kol_name, version_num, 2)
                st.download_button("ä¸‹è½½ - å¯å‘ç»™å®¢æˆ·", buffer, f"{output_name}.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", key="dl_kol")

with col_right:
    st.markdown('<span class="step-badge-green">Step 2: å®¢æˆ·åé¦ˆ - èµæ„å¤„ç† - å®Œæ¯•ç»™KOL</span>', unsafe_allow_html=True)
    st.markdown("#### ğŸ’¬ ä¸Šä¼ å®¢æˆ·åé¦ˆ")

    client_file = st.file_uploader("ä¸Šä¼  .docx", type=["docx"], key="client_file")
    client_text = st.text_area("æˆ–ç²˜è´´å†…å®¹", height=180, placeholder="ç²˜è´´å®¢æˆ·åé¦ˆ...", key="client_text")

    client_content = ""
    if client_file:
        client_file.seek(0)
        client_content = read_docx(client_file)
        st.success(f"å·²è¯»å–: {client_file.name}")
    elif client_text:
        client_content = client_text

    if st.button("åˆ†æåé¦ˆ", type="primary", key="btn_analyze", use_container_width=True):
        if not kol_name:
            st.error("è¯·å¡«å†™KOLåç§°")
        elif not client_content:
            st.error("è¯·ä¸Šä¼ æˆ–ç²˜è´´å®¢æˆ·åé¦ˆ")
        elif not st.session_state.kol_content:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ KOLåŸç¨¿")
        else:
            with st.spinner("AIåˆ†æä¸­..."):
                analysis = analyze_client_feedback(st.session_state.kol_content, client_content)
                st.session_state.client_analysis = analysis

    if st.session_state.client_analysis:
        st.markdown("#### ä¿®æ”¹åˆ†æ")

        if "===ä¿®æ”¹åˆ†æ===" in st.session_state.client_analysis:
            parts = st.session_state.client_analysis.split("===æ€»ç»“===")
            analysis_part = parts[0].replace("===ä¿®æ”¹åˆ†æ===", "").strip()

            lines = analysis_part.split("\n")
            changes = []
            current = {}
            for line in lines:
                line = line.strip()
                if line.startswith("ä¿®æ”¹"):
                    if current:
                        changes.append(current)
                    current = {"desc": line, "status": "", "suggestion": ""}
                elif line.startswith("çŠ¶æ€:"):
                    current["status"] = line.replace("çŠ¶æ€:", "").strip()
                elif line.startswith("å»ºè®®:"):
                    current["suggestion"] = line.replace("å»ºè®®:", "").strip()
            if current:
                changes.append(current)

            for i, c in enumerate(changes):
                is_ok = "ç¬¦åˆ" in c.get("status", "")
                st.checkbox(f"{'âœ…' if is_ok else 'âš ï¸'} {c.get('desc', '')}", key=f"cc_{i}", value=is_ok)
                if c.get("suggestion"):
                    st.caption(c["suggestion"])

            if len(parts) > 1:
                st.info(parts[1].strip())
        else:
            st.write(st.session_state.client_analysis)

        if kol_name and client_content:
            output_name = f"{kol_name}_{TODAY}_KOL-èµæ„-å®¢æˆ·_ç¬¬{version_num}ç‰ˆ"
            st.markdown(f'<div class="file-output">ğŸ“ {output_name}.docx</div>', unsafe_allow_html=True)

            if st.button("ç”Ÿæˆç»™KOLçš„æ–‡æ¡£", key="btn_gen_client", use_container_width=True):
                doc = Document()
                doc.add_heading(output_name, 0)
                doc.add_paragraph(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
                doc.add_paragraph("---")
                doc.add_heading("å®¢æˆ·ä¿®æ”¹åˆ†æ", level=1)
                doc.add_paragraph(st.session_state.client_analysis)
                doc.add_paragraph("---")
                doc.add_heading("ä¿®æ”¹åå†…å®¹", level=1)
                for line in client_content.split('\n'):
                    if line.strip():
                        doc.add_paragraph(line)
                buffer = io.BytesIO()
                doc.save(buffer)
                buffer.seek(0)
                st.download_button("ä¸‹è½½ - å¯å‘ç»™KOL", buffer, f"{output_name}.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", key="dl_client")

st.markdown("---")
st.caption("ğŸ¤– èµæ„AIå®¡ç¨¿ç³»ç»Ÿ v3.0")
