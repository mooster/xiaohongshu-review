import streamlit as st
import re
import os
import json
from datetime import datetime
from docx import Document
import io
import urllib.request

RULE_VERSION = "2026-02-04"
TODAY = datetime.now().strftime("%Y%m%d")

REVIEW_RULES = {
    "required_keywords": ["é€‚åº¦æ°´è§£", "é˜²æ•", "èƒ½æ©å…¨æŠ¤"],
    "forbidden_words": {
        "ç¦æ­¢è¯": ["æ•å®", "å¥¶ç“¶", "å¥¶å˜´", "æ–°ç”Ÿå„¿", "è¿‡æ•", "ç–¾ç—…"],
        "ç¦ç–—æ•ˆ": ["é¢„é˜²", "ç”Ÿé•¿", "å‘è‚²", "å…ç–«"],
        "ç¦ç»å¯¹åŒ–": ["æœ€å¥½", "æœ€ä½³", "TOP1", "No.1"]
    },
    "allowed_exceptions": ["ç¬¬ä¸€å£å¥¶ç²‰", "ç¬¬ä¸€å£é…æ–¹ç²‰"],
    "selling_points": [
        "å¤šé¡¹ç§‘å­¦å®è¯çš„é›€å·¢å°–å³°æ°´è§£æŠ€æœ¯",
        "é˜²æ•é¢†åŸŸæƒå¨å¾·å›½GINIç ”ç©¶è®¤è¯",
        "èƒ½é•¿æ•ˆé˜²æ•20å¹´",
        "ç›¸æ¯”äºç‰›å¥¶è›‹ç™½è‡´æ•æ€§é™ä½1000å€",
        "å…¨çƒåˆ›æ–°çš„è¶…å€è‡ªæŠ¤ç§‘æŠ€",
        "6ç§HMOåŠ ä¸Šæ˜æ˜ŸåŒèŒB.Infantiså’ŒBb-12",
        "ååŒä½œç”¨é‡Šæ”¾é«˜å€çš„åŸç”Ÿä¿æŠ¤åŠ›",
        "çŸ­çŸ­28å¤©å°±èƒ½è°ƒç†å¥½å¨ƒçš„è‚šè‚šèŒèŒç¯å¢ƒ",
        "ä¿æŠ¤åŠ›èƒ½æŒç»­15ä¸ªæœˆ",
        "25ç§ç»´ç”Ÿç´ å’ŒçŸ¿ç‰©è´¨",
        "å…¨ä¹³ç³–çš„é…æ–¹å£å‘³æ¸…æ·¡"
    ],
    "required_tags": ["#èƒ½æ©å…¨æŠ¤", "#èƒ½æ©å…¨æŠ¤æ°´å¥¶", "#é€‚åº¦æ°´è§£", "#é€‚åº¦æ°´è§£å¥¶ç²‰", "#é€‚åº¦æ°´è§£å¥¶ç²‰æ¨è", "#é˜²æ•å¥¶ç²‰", "#ç¬¬ä¸€å£å¥¶ç²‰", "#é›€å·¢é€‚åº¦æ°´è§£"],
    "max_words": 900,
    "min_tags": 10
}

SUGGESTIONS = {"æ•å®": "æ•æ„Ÿä½“è´¨å®å®", "æ–°ç”Ÿå„¿": "åˆç”Ÿå®å®", "è¿‡æ•": "æ•æ•", "é¢„é˜²": "è¿œç¦»", "ç”Ÿé•¿": "æˆé•¿", "å‘è‚²": "æˆé•¿", "å…ç–«": "ä¿æŠ¤åŠ›"}

def read_docx(file):
    doc = Document(io.BytesIO(file.read()))
    text = []
    for para in doc.paragraphs:
        if para.text.strip():
            text.append(para.text)
    return "\n".join(text)

def parse_content(content):
    tags = re.findall(r'#[\w\u4e00-\u9fff]+', content)
    text = re.sub(r'#[\w\u4e00-\u9fff]+', '', content)
    word_count = len(re.findall(r'[\u4e00-\u9fff]', text))
    return {"text": content, "tags": tags, "word_count": word_count}

def run_review(content):
    data = parse_content(content)
    issues = []

    for kw in REVIEW_RULES["required_keywords"]:
        if kw not in data["text"]:
            issues.append({"type": "keyword", "desc": f"ç¼ºå°‘å…³é”®è¯: {kw}", "suggestion": f"è¯·åŠ å…¥ã€Œ{kw}ã€"})

    exceptions = REVIEW_RULES["allowed_exceptions"]
    for cat, words in REVIEW_RULES["forbidden_words"].items():
        for w in words:
            if w in data["text"]:
                idx = data["text"].find(w)
                ctx = data["text"][max(0,idx-10):idx+len(w)+10]
                if not any(e in ctx for e in exceptions):
                    sug = SUGGESTIONS.get(w, "åˆ é™¤")
                    issues.append({"type": "forbidden", "desc": f"ç¦è¯ã€Œ{w}ã€", "context": ctx, "suggestion": f"æ”¹ä¸ºã€Œ{sug}ã€"})

    for sp in REVIEW_RULES["selling_points"]:
        if sp not in data["text"]:
            issues.append({"type": "selling", "desc": f"ç¼ºå°‘å–ç‚¹", "suggestion": f"è¯·åŠ å…¥: {sp}"})

    if data["word_count"] > REVIEW_RULES["max_words"]:
        issues.append({"type": "structure", "desc": f"å­—æ•°è¶…é™: {data['word_count']}/{REVIEW_RULES['max_words']}", "suggestion": "è¯·ç²¾ç®€"})

    if len(data["tags"]) < REVIEW_RULES["min_tags"]:
        issues.append({"type": "structure", "desc": f"æ ‡ç­¾ä¸è¶³: {len(data['tags'])}/{REVIEW_RULES['min_tags']}", "suggestion": "è¯·è¡¥å……"})

    for t in REVIEW_RULES["required_tags"]:
        if t not in data["tags"]:
            issues.append({"type": "tag", "desc": f"ç¼ºå°‘æ ‡ç­¾: {t}", "suggestion": f"è¯·åŠ å…¥ {t}"})

    return issues, data

def call_claude_api(prompt):
    api_key = os.environ.get("ANTHROPIC_API_KEY")
    if not api_key:
        return None
    url = "https://api.anthropic.com/v1/messages"
    headers = {"Content-Type": "application/json", "x-api-key": api_key, "anthropic-version": "2023-06-01"}
    data = {"model": "claude-sonnet-4-20250514", "max_tokens": 4000, "messages": [{"role": "user", "content": prompt}]}
    req = urllib.request.Request(url, data=json.dumps(data).encode('utf-8'), headers=headers)
    try:
        with urllib.request.urlopen(req, timeout=60) as response:
            result = json.loads(response.read().decode('utf-8'))
            return result["content"][0]["text"]
    except Exception as e:
        return f"Error: {str(e)}"

def analyze_client_feedback(original, client_modified):
    prompt = f"""ä½ æ˜¯å°çº¢ä¹¦KOLç¨¿ä»¶å®¡æ ¸ä¸“å®¶ã€‚å¯¹æ¯”åˆ†æå®¢æˆ·ä¿®æ”¹ã€‚

åŸç¨¿ä»¶:
{original}

å®¢æˆ·ä¿®æ”¹å:
{client_modified}

å®¡æ ¸è§„åˆ™: ç¦è¯åŒ…æ‹¬æ•å®ã€å¥¶ç“¶ã€å¥¶å˜´ã€æ–°ç”Ÿå„¿ã€è¿‡æ•ã€ç–¾ç—…ã€é¢„é˜²ã€ç”Ÿé•¿ã€å‘è‚²ã€å…ç–«ã€æœ€å¥½ã€æœ€ä½³ã€‚ä¾‹å¤–:"ç¬¬ä¸€å£å¥¶ç²‰"ä¸­çš„"ç¬¬ä¸€"ä¸ç®—ç¦è¯ã€‚

è¯·åˆ†æå®¢æˆ·ä¿®æ”¹äº†å“ªäº›å†…å®¹,æ¯æ¡æ˜¯å¦ç¬¦åˆè§„åˆ™,ä¸ç¬¦åˆçš„ç»™å»ºè®®ã€‚

æ ¼å¼:
===ä¿®æ”¹åˆ†æ===
ä¿®æ”¹1: [æè¿°]
çŠ¶æ€: ç¬¦åˆ/ä¸ç¬¦åˆ
å»ºè®®: [å»ºè®®]

===æ€»ç»“===
ç¬¦åˆ: Xæ¡
éœ€è°ƒæ•´: Xæ¡
"""
    return call_claude_api(prompt)

def create_annotated_docx(content, issues, selected_issues, kol_name, version, step, extra_comments=None):
    doc = Document()
    if step == 2:
        title = f"{kol_name}_{TODAY}_KOL-èµæ„_ç¬¬{version}ç‰ˆ"
        subtitle = "èµæ„å®¡æ ¸æ‰¹æ³¨ç‰ˆ"
    else:
        title = f"{kol_name}_{TODAY}_KOL-èµæ„-å®¢æˆ·_ç¬¬{version}ç‰ˆ"
        subtitle = "å®¢æˆ·åé¦ˆå¤„ç†ç‰ˆ"

    doc.add_heading(title, 0)
    doc.add_paragraph(f"å®¡æ ¸æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    doc.add_paragraph(f"æ–‡æ¡£ç±»å‹: {subtitle}")
    doc.add_paragraph("---")

    if selected_issues:
        doc.add_heading("å®¡æ ¸æ„è§ï¼ˆå·²é‡‡çº³ï¼‰", level=1)
        for i, idx in enumerate(selected_issues):
            if idx < len(issues):
                issue = issues[idx]
                p = doc.add_paragraph()
                p.add_run(f"{i+1}. {issue['desc']}").bold = True
                p.add_run(f"\n   å»ºè®®: {issue['suggestion']}")
        doc.add_paragraph("---")

    if extra_comments:
        doc.add_heading("è¡¥å……æ„è§", level=1)
        doc.add_paragraph(extra_comments)
        doc.add_paragraph("---")

    doc.add_heading("ç¨¿ä»¶å†…å®¹", level=1)
    for line in content.split('\n'):
        if line.strip():
            doc.add_paragraph(line)

    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer, title

# ========== é¡µé¢é…ç½® ==========
st.set_page_config(page_title="èµæ„AIå®¡ç¨¿ç³»ç»Ÿ", page_icon="ğŸ¤–", layout="wide")

st.markdown("""
<style>
.block-container {padding-top: 1rem !important; padding-bottom: 1rem !important;}
/* æ–‡ä»¶ä¸Šä¼ ä¸­æ–‡åŒ– */
[data-testid="stFileUploader"] [data-testid="stFileUploaderDropzone"] p {
    font-size: 0 !important;
}
[data-testid="stFileUploader"] [data-testid="stFileUploaderDropzone"] p::after {
    content: "å°†æ–‡ä»¶æ‹–åˆ°æ­¤å¤„ä¸Šä¼ ";
    font-size: 14px !important;
}
[data-testid="stFileUploader"] [data-testid="stFileUploaderDropzone"] button {
    font-size: 0 !important;
    position: relative;
}
[data-testid="stFileUploader"] [data-testid="stFileUploaderDropzone"] button::after {
    content: "é€‰æ‹©æ–‡ä»¶";
    font-size: 14px !important;
    position: absolute;
}
/* ä¸Šä¼ åŒºæ ·å¼ */
.upload-section {
    background-color: #f8f9fa;
    border-radius: 12px;
    padding: 20px;
    border: 1px solid #e2e8f0;
}
/* ç»¿è‰²æŒ‰é’®æ ·å¼ */
.green-btn button {
    background-color: #38a169 !important;
    color: white !important;
    border: none !important;
}
.green-btn button:hover {
    background-color: #2f855a !important;
}
/* å®¡æ ¸é¢„è§ˆåŒº */
.review-panel {
    background: linear-gradient(135deg, #667eea10, #764ba210);
    border: 2px solid #667eea;
    border-radius: 15px;
    padding: 25px;
    margin: 20px 0;
}
.original-text-box {
    background-color: #ffffff;
    border: 1px solid #e2e8f0;
    border-radius: 10px;
    padding: 15px;
    height: 400px;
    overflow-y: auto;
    font-size: 14px;
    line-height: 1.8;
}
.issue-card {
    background-color: #fff5f5;
    border-left: 4px solid #fc8181;
    padding: 10px 15px;
    margin: 6px 0;
    border-radius: 0 8px 8px 0;
    font-size: 13px;
}
.issue-card.accepted {
    background-color: #f0fff4;
    border-left-color: #68d391;
}
.stat-box {
    background-color: #edf2f7;
    border-radius: 8px;
    padding: 10px 15px;
    text-align: center;
    font-weight: bold;
}
</style>
""", unsafe_allow_html=True)

# ========== æ ‡é¢˜ ==========
st.markdown("""
<div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 12px; padding: 15px 25px; margin-bottom: 15px;">
    <h2 style="color: white; margin: 0;">ğŸ¤– èµæ„AI Â· å°çº¢ä¹¦KOLå®¡ç¨¿ç³»ç»Ÿ</h2>
    <p style="color: rgba(255,255,255,0.9); margin: 5px 0 0 0; font-size: 15px;">å…”å­å°å§ï¼Œä½ å¥½å‘€ï¼æˆ‘æ˜¯èƒ½æ©å…¨æŠ¤çš„AIæœºå™¨äººï¼Œä¸ºä½ æœåŠ¡~</p>
</div>
""", unsafe_allow_html=True)

# ========== åŸºæœ¬ä¿¡æ¯ ==========
col1, col2, col3 = st.columns([2, 1, 1])
with col1:
    kol_name = st.text_input("KOLåç§°", placeholder="ä¾‹å¦‚: å›¢å¦ˆçˆ±æµ‹è¯„")
with col2:
    version_num = st.selectbox("å½“å‰ç‰ˆæœ¬", [1, 2, 3, 4, 5])
with col3:
    st.caption(f"å½“å‰æ—¥æœŸ: {TODAY}")

# ========== Session State åˆå§‹åŒ– ==========
if 'kol_issues' not in st.session_state:
    st.session_state.kol_issues = []
if 'kol_content' not in st.session_state:
    st.session_state.kol_content = ""
if 'kol_data' not in st.session_state:
    st.session_state.kol_data = None
if 'client_analysis' not in st.session_state:
    st.session_state.client_analysis = ""
if 'client_content_saved' not in st.session_state:
    st.session_state.client_content_saved = ""

# ========== ä¸Šä¼ åŒºï¼šå·¦å³ä¸¤æ  ==========
col_left, col_right = st.columns(2)

with col_left:
    st.markdown("#### ğŸ“„ Step 1: ä¸Šä¼ KOLç¨¿ä»¶")
    kol_file = st.file_uploader("ä¸Šä¼  .docx æ–‡ä»¶ï¼ˆå¯æ‹–æ‹½ä¸Šä¼ ï¼‰", type=["docx"], key="kol_file")
    kol_text = st.text_area("æˆ–ç²˜è´´å†…å®¹", height=120, placeholder="ç²˜è´´KOLç¨¿ä»¶...", key="kol_text")

    kol_content = ""
    if kol_file:
        kol_file.seek(0)
        kol_content = read_docx(kol_file)
        st.success(f"å·²è¯»å–: {kol_file.name}")
    elif kol_text:
        kol_content = kol_text

    if st.button("å¼€å§‹å®¡ç¨¿", type="primary", key="btn_review", use_container_width=True):
        if not kol_name:
            st.error("è¯·å¡«å†™KOLåç§°")
        elif not kol_content:
            st.error("è¯·ä¸Šä¼ æˆ–ç²˜è´´ç¨¿ä»¶")
        else:
            issues, data = run_review(kol_content)
            st.session_state.kol_issues = issues
            st.session_state.kol_content = kol_content
            st.session_state.kol_data = data
            st.success(f"å®¡æ ¸å®Œæˆ! å‘ç° {len(issues)} ä¸ªé—®é¢˜")

with col_right:
    st.markdown("#### ğŸ’¬ Step 2: ä¸Šä¼ å®¢æˆ·åé¦ˆ")
    client_file = st.file_uploader("ä¸Šä¼  .docx æ–‡ä»¶ï¼ˆå¯æ‹–æ‹½ä¸Šä¼ ï¼‰", type=["docx"], key="client_file")
    client_text = st.text_area("æˆ–ç²˜è´´å†…å®¹", height=120, placeholder="ç²˜è´´å®¢æˆ·åé¦ˆ...", key="client_text")

    client_content = ""
    if client_file:
        client_file.seek(0)
        client_content = read_docx(client_file)
        st.success(f"å·²è¯»å–: {client_file.name}")
    elif client_text:
        client_content = client_text

    st.markdown('<div class="green-btn">', unsafe_allow_html=True)
    analyze_clicked = st.button("åˆ†æåé¦ˆ", key="btn_analyze", use_container_width=True)
    st.markdown('</div>', unsafe_allow_html=True)

    if analyze_clicked:
        if not kol_name:
            st.error("è¯·å¡«å†™KOLåç§°")
        elif not client_content:
            st.error("è¯·ä¸Šä¼ æˆ–ç²˜è´´å®¢æˆ·åé¦ˆ")
        elif not st.session_state.kol_content:
            st.error("è¯·å…ˆä¸Šä¼ KOLåŸç¨¿å¹¶å®¡æ ¸")
        else:
            st.session_state.client_content_saved = client_content
            with st.spinner("AIåˆ†æä¸­..."):
                analysis = analyze_client_feedback(st.session_state.kol_content, client_content)
                st.session_state.client_analysis = analysis

# ========== å®¡æ ¸é¢„è§ˆåŒºï¼ˆå…¨å®½ï¼Œæ¨ªè·¨ä¸¤æ ï¼‰ ==========
if st.session_state.kol_issues and st.session_state.kol_content:
    st.markdown("---")
    st.markdown("### ğŸ“‹ åœ¨çº¿å®¡æ ¸é¢„è§ˆ")

    # ç»Ÿè®¡æ 
    total = len(st.session_state.kol_issues)
    data = st.session_state.kol_data
    word_count = data["word_count"] if data else 0
    tag_count = len(data["tags"]) if data else 0

    s1, s2, s3, s4 = st.columns(4)
    s1.metric("å®¡æ ¸é—®é¢˜", f"{total} æ¡")
    s2.metric("ç¨¿ä»¶å­—æ•°", f"{word_count}")
    s3.metric("æ ‡ç­¾æ•°é‡", f"{tag_count}")
    s4.metric("å­—æ•°ä¸Šé™", f"{REVIEW_RULES['max_words']}")

    # å·¦ï¼šåŸæ–‡ | å³ï¼šå®¡æ ¸æ„è§
    preview_left, preview_right = st.columns([1, 1])

    with preview_left:
        st.markdown("#### ğŸ“„ ç¨¿ä»¶åŸæ–‡")
        # æŠŠåŸæ–‡ä¸­çš„ç¦è¯é«˜äº®æ˜¾ç¤º
        highlighted = st.session_state.kol_content
        for cat, words in REVIEW_RULES["forbidden_words"].items():
            for w in words:
                if w in highlighted:
                    highlighted = highlighted.replace(w, f'<mark style="background-color:#fed7d7;padding:2px 4px;border-radius:3px;">{w}</mark>')
        # æŠŠå¿…å«å…³é”®è¯é«˜äº®
        for kw in REVIEW_RULES["required_keywords"]:
            if kw in highlighted:
                highlighted = highlighted.replace(kw, f'<mark style="background-color:#c6f6d5;padding:2px 4px;border-radius:3px;">{kw}</mark>')

        html_content = highlighted.replace('\n', '<br>')
        st.markdown(f'<div class="original-text-box">{html_content}</div>', unsafe_allow_html=True)

    with preview_right:
        st.markdown("#### âœï¸ å®¡æ ¸æ„è§ï¼ˆå‹¾é€‰é‡‡çº³ï¼‰")

        issue_types = {"keyword": "ğŸ”‘ å…³é”®è¯", "forbidden": "ğŸš« ç¦è¯", "selling": "ğŸ’¡ å–ç‚¹", "structure": "ğŸ“ ç»“æ„", "tag": "ğŸ·ï¸ æ ‡ç­¾"}
        selected = []

        # æŒ‰ç±»å‹åˆ†ç»„
        grouped = {}
        for i, issue in enumerate(st.session_state.kol_issues):
            t = issue["type"]
            if t not in grouped:
                grouped[t] = []
            grouped[t].append((i, issue))

        for issue_type, items in grouped.items():
            type_label = issue_types.get(issue_type, issue_type)
            with st.expander(f"{type_label} ({len(items)}æ¡)", expanded=(issue_type in ["forbidden", "keyword"])):
                for i, issue in items:
                    checked = st.checkbox(issue["desc"], key=f"iss_{i}", value=True)
                    if checked:
                        selected.append(i)
                    st.caption(f"å»ºè®®: {issue['suggestion']}")

    # è¡¥å……æ„è§ + ç”Ÿæˆæ–‡æ¡£ï¼ˆå…¨å®½ï¼‰
    st.markdown("---")
    comment_col, action_col = st.columns([2, 1])

    with comment_col:
        st.markdown("#### ğŸ’¬ è¡¥å……æ„è§ï¼ˆå¯é€‰ï¼‰")
        extra_comments = st.text_area("è¾“å…¥é¢å¤–çš„å®¡æ ¸æ„è§æˆ–å¤‡æ³¨", height=80, placeholder="ä¾‹å¦‚: æ•´ä½“è¯­æ°”åç¡¬ï¼Œå»ºè®®æ›´å£è¯­åŒ–ä¸€äº›...", key="extra_comments")

    with action_col:
        st.markdown("#### ğŸ“Š å®¡æ ¸ç»Ÿè®¡")
        accepted = len(selected)
        st.markdown(f"å·²é‡‡çº³ **{accepted}** / {total} æ¡")
        st.progress(accepted / total if total > 0 else 0)

        if kol_name:
            output_name = f"{kol_name}_{TODAY}_KOL-èµæ„_ç¬¬{version_num}ç‰ˆ"
            st.markdown(f"`ğŸ“ {output_name}.docx`")

            if st.button("ç¡®è®¤å¹¶ç”Ÿæˆæ‰¹æ³¨æ–‡æ¡£", key="btn_gen_kol", use_container_width=True, type="primary"):
                buffer, title = create_annotated_docx(
                    st.session_state.kol_content,
                    st.session_state.kol_issues,
                    selected, kol_name, version_num, 2,
                    extra_comments if extra_comments else None
                )
                st.download_button("ä¸‹è½½æ–‡æ¡£ - å¯å‘ç»™å®¢æˆ·", buffer, f"{output_name}.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", key="dl_kol")

# ========== å®¢æˆ·åé¦ˆåˆ†æåŒºï¼ˆå…¨å®½ï¼‰ ==========
if st.session_state.client_analysis:
    st.markdown("---")
    st.markdown("### ğŸ’¬ å®¢æˆ·åé¦ˆåˆ†æ")

    feedback_left, feedback_right = st.columns([1, 1])

    with feedback_left:
        st.markdown("#### ğŸ“„ å®¢æˆ·ä¿®æ”¹å†…å®¹")
        if st.session_state.client_content_saved:
            st.markdown(f'<div class="original-text-box">{st.session_state.client_content_saved.replace(chr(10), "<br>")}</div>', unsafe_allow_html=True)

    with feedback_right:
        st.markdown("#### âœï¸ ä¿®æ”¹åˆ†æ")
        if "===ä¿®æ”¹åˆ†æ===" in st.session_state.client_analysis:
            parts = st.session_state.client_analysis.split("===æ€»ç»“===")
            analysis_part = parts[0].replace("===ä¿®æ”¹åˆ†æ===", "").strip()

            lines = analysis_part.split("\n")
            changes = []
            current = {}
            for line in lines:
                line = line.strip()
                if line.startswith("ä¿®æ”¹"):
                    if current:
                        changes.append(current)
                    current = {"desc": line, "status": "", "suggestion": ""}
                elif line.startswith("çŠ¶æ€:"):
                    current["status"] = line.replace("çŠ¶æ€:", "").strip()
                elif line.startswith("å»ºè®®:"):
                    current["suggestion"] = line.replace("å»ºè®®:", "").strip()
            if current:
                changes.append(current)

            for i, c in enumerate(changes):
                is_ok = "ç¬¦åˆ" in c.get("status", "")
                checked = st.checkbox(c.get('desc', ''), key=f"cc_{i}", value=is_ok)
                status_icon = "âœ…" if is_ok else "âš ï¸"
                if c.get("suggestion"):
                    st.caption(f"{status_icon} {c['suggestion']}")

            if len(parts) > 1:
                st.info(parts[1].strip())
        else:
            st.write(st.session_state.client_analysis)

    # è¡¥å……æ„è§ + ç”Ÿæˆ
    st.markdown("---")
    fc_col, fa_col = st.columns([2, 1])

    with fc_col:
        st.markdown("#### ğŸ’¬ è¡¥å……æ„è§ç»™KOLï¼ˆå¯é€‰ï¼‰")
        client_extra = st.text_area("è¾“å…¥é¢å¤–çš„åé¦ˆæ„è§", height=80, placeholder="ä¾‹å¦‚: å®¢æˆ·å¸Œæœ›ç¬¬3å¼ å›¾ç‰‡çªå‡ºäº§å“åŒ…è£…...", key="client_extra")

    with fa_col:
        if kol_name:
            output_name = f"{kol_name}_{TODAY}_KOL-èµæ„-å®¢æˆ·_ç¬¬{version_num}ç‰ˆ"
            st.markdown(f"`ğŸ“ {output_name}.docx`")

            if st.button("ç¡®è®¤å¹¶ç”Ÿæˆç»™KOLçš„æ–‡æ¡£", key="btn_gen_client", use_container_width=True, type="primary"):
                doc = Document()
                doc.add_heading(output_name, 0)
                doc.add_paragraph(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
                doc.add_paragraph("---")
                doc.add_heading("å®¢æˆ·ä¿®æ”¹åˆ†æ", level=1)
                doc.add_paragraph(st.session_state.client_analysis)
                if client_extra:
                    doc.add_paragraph("---")
                    doc.add_heading("è¡¥å……æ„è§", level=1)
                    doc.add_paragraph(client_extra)
                doc.add_paragraph("---")
                doc.add_heading("ä¿®æ”¹åå†…å®¹", level=1)
                saved = st.session_state.client_content_saved
                for line in saved.split('\n'):
                    if line.strip():
                        doc.add_paragraph(line)
                buffer = io.BytesIO()
                doc.save(buffer)
                buffer.seek(0)
                st.download_button("ä¸‹è½½æ–‡æ¡£ - å¯å‘ç»™KOL", buffer, f"{output_name}.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", key="dl_client")

st.markdown("---")
st.caption("ğŸ¤– èµæ„AIå®¡ç¨¿ç³»ç»Ÿ v3.2")
